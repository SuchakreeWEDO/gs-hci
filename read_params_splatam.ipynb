{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = r\"D:\\3d-reconstruction\\datasets\\splatam-nerf-03052024\\params.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = np.load(src)\n",
    "\n",
    "xyz     = params['means3D']\n",
    "normals = np.zeros_like(xyz)\n",
    "f_dc    = params['rgb_colors']\n",
    "opacities = params['logit_opacities']\n",
    "scale     = params['log_scales'].repeat(3, axis=-1)\n",
    "rotation  = params['unnorm_rotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"orig_xyz_from_npz.npy\", xyz)\n",
    "np.save(\"orig_rgb_from_npz.npy\", f_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Edit points in params.npz to match the points that we got from training 3DGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['means3D', 'rgb_colors', 'unnorm_rotations', 'logit_opacities', 'log_scales', 'cam_unnorm_rots', 'cam_trans', 'timestep', 'intrinsics', 'w2c', 'org_width', 'org_height', 'gt_w2c_all_frames', 'keyframe_time_indices']\n"
     ]
    }
   ],
   "source": [
    "print(list(params.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means3D (861743, 3)\n",
      "rgb_colors (861743, 3)\n",
      "unnorm_rotations (861743, 4)\n",
      "logit_opacities (861743, 1)\n",
      "log_scales (861743, 1)\n",
      "cam_unnorm_rots (1, 4, 50)\n",
      "cam_trans (1, 3, 50)\n",
      "timestep (861743,)\n",
      "intrinsics (3, 3)\n",
      "w2c (4, 4)\n",
      "org_width ()\n",
      "org_height ()\n",
      "gt_w2c_all_frames (50, 4, 4)\n",
      "keyframe_time_indices (12,)\n"
     ]
    }
   ],
   "source": [
    "for k in list(params.keys()) :\n",
    "    print(k, params[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0000000e+00,  1.8626451e-09,  2.7755579e-17, -4.4703484e-08],\n",
       "       [-1.8626454e-09,  1.0000000e+00,  1.4901163e-08,  1.4901161e-08],\n",
       "       [-1.4901163e-08, -2.7755579e-17,  1.0000001e+00, -1.4901161e-08],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['gt_w2c_all_frames'][0,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chana\\anaconda3\\envs\\gs_viser\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0.]])\n",
      "[[ 2.22044605e-16 -1.00000000e+00  0.00000000e+00]\n",
      " [ 1.00000000e+00  2.22044605e-16  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "tensor([[0., 0., 0.]])\n",
      "tensor([[ 1.0000e+00,  1.8626e-09,  2.7756e-17, -4.4703e-08],\n",
      "        [-1.8626e-09,  1.0000e+00,  1.4901e-08,  1.4901e-08],\n",
      "        [-1.4901e-08, -2.7756e-17,  1.0000e+00, -1.4901e-08],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]])\n",
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "\n",
    "first_frame_R = torch.tensor(params['cam_unnorm_rots'][:,:,0])\n",
    "print(first_frame_R)\n",
    "\n",
    "r = Rotation.from_rotvec(np.pi/2 * np.array([0, 0, 1]))\n",
    "R_matrix = r.as_matrix()\n",
    "print(R_matrix)\n",
    "\n",
    "first_frame_T = torch.tensor(params['cam_trans'][:,:,0])\n",
    "print(first_frame_T)\n",
    "\n",
    "first_frame_w2c = torch.tensor(params['w2c'])\n",
    "print(first_frame_w2c)\n",
    "print(first_frame_w2c.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000e+00, -1.8626e-09, -0.0000e+00,  4.4703e-08],\n",
      "        [ 1.8626e-09,  1.0000e+00, -1.4901e-08, -1.4901e-08],\n",
      "        [ 1.4901e-08,  0.0000e+00,  1.0000e+00,  1.4901e-08],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chana\\AppData\\Local\\Temp\\ipykernel_17704\\2887472891.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  first_frame_c2w =  torch.linalg.inv((torch.tensor(first_frame_w2c.clone().detach())))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "first_frame_c2w =  torch.linalg.inv((torch.tensor(first_frame_w2c.clone().detach())))\n",
    "print(first_frame_c2w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9940, -0.7202,  1.3847,  1.0000],\n",
      "        [-0.9648, -0.7453,  1.4508,  1.0000],\n",
      "        [-0.9591, -0.7529,  1.4637,  1.0000],\n",
      "        ...,\n",
      "        [-2.0291, -0.5660,  3.0558,  1.0000],\n",
      "        [-1.6353, -0.4126,  2.9322,  1.0000],\n",
      "        [-1.6313, -0.3694,  2.8564,  1.0000]])\n",
      "torch.Size([861743, 4])\n"
     ]
    }
   ],
   "source": [
    "points = torch.tensor(params['means3D'])\n",
    "ones = torch.ones((points.shape[0], 1))\n",
    "\n",
    "points_ones = torch.cat((points, ones), dim=1)\n",
    "\n",
    "print(points_ones)\n",
    "print(points_ones.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.9940368  -0.72022104  1.384701  ]\n",
      " [-0.9647725  -0.7452825   1.450773  ]\n",
      " [-0.95910203 -0.75287193  1.4637486 ]\n",
      " ...\n",
      " [-2.029058   -0.5659783   3.055822  ]\n",
      " [-1.6353457  -0.4126091   2.9322371 ]\n",
      " [-1.6313092  -0.369389    2.8564053 ]]\n"
     ]
    }
   ],
   "source": [
    "# Invert the W2C transformation matrix to get C2W\n",
    "C2W_matrix = np.linalg.inv(first_frame_w2c)\n",
    "\n",
    "# Convert points from camera space to world space\n",
    "points_world = np.dot(C2W_matrix, points_ones.T).T[:, :3]\n",
    "print(points_world)\n",
    "\n",
    "\n",
    "np.save(\"points_world.npy\", points_world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True, False],\n",
       "        [False,  True, False],\n",
       "        [False,  True, False],\n",
       "        ...,\n",
       "        [ True, False, False],\n",
       "        [ True, False, False],\n",
       "        [ True, False, False]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eq(points, torch.tensor(points_world))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0000000e+00, -1.8626451e-09,  0.0000000e+00,  4.4703484e-08],\n",
       "       [ 1.8626451e-09,  1.0000000e+00, -1.4901161e-08, -1.4901161e-08],\n",
       "       [ 1.4901161e-08,  0.0000000e+00,  9.9999988e-01,  1.4901160e-08],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C2W_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original point: [-0.39235845 -0.2755367   1.3324081 ]\n",
      "Transformed point: [-0.39235841 -0.27553672  1.33240792]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def transform_point(point, transformation_matrix):\n",
    "    # Convert the point to homogeneous coordinates (append 1)\n",
    "    point = np.append(point, 1)\n",
    "    \n",
    "    # Perform matrix multiplication\n",
    "    transformed_point = np.dot(transformation_matrix, point)\n",
    "    \n",
    "    # Normalize the result by dividing by the fourth component\n",
    "    transformed_point /= transformed_point[-1]\n",
    "    \n",
    "    # Return the transformed point without the homogeneous coordinate\n",
    "    return transformed_point[:-1]\n",
    "\n",
    "\n",
    "# Example 3D point\n",
    "point = np.array([1,2,3])\n",
    "\n",
    "# Apply transformation\n",
    "transformed_point = transform_point(point, transformation_matrix)\n",
    "\n",
    "print(\"Original point:\", point)\n",
    "print(\"Transformed point:\", transformed_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9940, -0.7202,  1.3847,  1.0000],\n",
      "        [-0.9648, -0.7453,  1.4508,  1.0000],\n",
      "        [-0.9591, -0.7529,  1.4637,  1.0000],\n",
      "        ...,\n",
      "        [-2.0291, -0.5660,  3.0558,  1.0000],\n",
      "        [-1.6353, -0.4126,  2.9322,  1.0000],\n",
      "        [-1.6313, -0.3694,  2.8564,  1.0000]])\n"
     ]
    }
   ],
   "source": [
    "points_c2w = torch.matmul(points_ones, first_frame_c2w)\n",
    "print(points_c2w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9940, -0.7202,  1.3847,  1.0000],\n",
      "        [-0.9648, -0.7453,  1.4508,  1.0000],\n",
      "        [-0.9591, -0.7529,  1.4637,  1.0000],\n",
      "        ...,\n",
      "        [-2.0291, -0.5660,  3.0558,  1.0000],\n",
      "        [-1.6353, -0.4126,  2.9322,  1.0000],\n",
      "        [-1.6313, -0.3694,  2.8564,  1.0000]])\n"
     ]
    }
   ],
   "source": [
    "points_w2c = torch.matmul(points_ones, first_frame_w2c)\n",
    "print(points_w2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed_point_cloud = (first_frame_R @ points) + first_frame_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00, -1.8626e-09, -0.0000e+00,  4.4703e-08],\n",
       "        [ 1.8626e-09,  1.0000e+00, -1.4901e-08, -1.4901e-08],\n",
       "        [ 1.4901e-08,  0.0000e+00,  1.0000e+00,  1.4901e-08],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_frame_c2w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00,  1.8626e-09,  2.7756e-17, -4.4703e-08],\n",
       "        [-1.8626e-09,  1.0000e+00,  1.4901e-08,  1.4901e-08],\n",
       "        [-1.4901e-08, -2.7756e-17,  1.0000e+00, -1.4901e-08],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_frame_w2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0026,  0.9902, -0.1395, -0.1498],\n",
      "        [-0.9880,  0.0190,  0.1535,  0.2498],\n",
      "        [ 0.1546,  0.1382,  0.9783,  0.0756],\n",
      "        [ 0.0000,  0.0000,  0.0000,  1.0000]])\n",
      "tensor([[-0.0026,  0.9902, -0.1395, -0.1498],\n",
      "        [-0.9880,  0.0190,  0.1535,  0.2498],\n",
      "        [ 0.1546,  0.1382,  0.9783,  0.0756],\n",
      "        [ 0.0000,  0.0000,  0.0000,  1.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.matmul(transform_matrix_first_frame,first_frame_c2w))\n",
    "print(torch.matmul(transform_matrix_first_frame,first_frame_w2c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0026,  0.9902, -0.1395, -0.1498],\n",
      "        [-0.9880,  0.0190,  0.1535,  0.2498],\n",
      "        [ 0.1546,  0.1382,  0.9783,  0.0756],\n",
      "        [ 0.0000,  0.0000,  0.0000,  1.0000]])\n",
      "tensor([[-0.0026,  0.9902, -0.1395, -0.1498],\n",
      "        [-0.9880,  0.0190,  0.1535,  0.2498],\n",
      "        [ 0.1546,  0.1382,  0.9783,  0.0756],\n",
      "        [ 0.0000,  0.0000,  0.0000,  1.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.matmul(first_frame_c2w @ transform_matrix_first_frame))\n",
    "print(torch.matmul(first_frame_w2c @ transform_matrix_first_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W2C\n",
    "def getWorld2View2(R, t, translate=np.array([.0, .0, .0]), scale=1.0):\n",
    "    Rt = np.zeros((4, 4))\n",
    "    Rt[:3, :3] = R.transpose()\n",
    "    Rt[:3, 3] = t\n",
    "    Rt[3, 3] = 1.0\n",
    "\n",
    "    C2W = np.linalg.inv(Rt)\n",
    "    cam_center = C2W[:3, 3]\n",
    "    cam_center = (cam_center + translate) * scale\n",
    "    C2W[:3, 3] = cam_center\n",
    "    Rt = np.linalg.inv(C2W)\n",
    "    return np.float32(Rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "# Define the camera transformation matrix\n",
    "M_camera = np.array([\n",
    "    [r11, r12, r13, tx],\n",
    "    [r21, r22, r23, ty],\n",
    "    [r31, r32, r33, tz],\n",
    "    [0,   0,   0,   1 ]\n",
    "])\n",
    " \n",
    "# Define the point in camera space (homogeneous coordinates)\n",
    "P_camera = np.array([x, y, z, 1])\n",
    " \n",
    "# Transform the point to world space\n",
    "P_world = np.dot(M_camera, P_camera)\n",
    " \n",
    "# Convert back to Cartesian coordinates if needed\n",
    "P_world_cartesian = P_world[:3] / P_world[3]\n",
    " \n",
    "print(\"Point in world space:\", P_world_cartesian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "966.8006591796875 722.9915161132812 1338.148681640625 1338.148681640625\n"
     ]
    }
   ],
   "source": [
    "# cameras.txt\n",
    "\n",
    "# height width\n",
    "import json\n",
    "json_file = open('../transforms.json')\n",
    "data = json.load(json_file)\n",
    "height = data['h']\n",
    "width  = data['w']\n",
    "\n",
    "FX = data['fl_x']\n",
    "FY  = data['fl_y']\n",
    "CX = data['cx']\n",
    "CY = data['cy']\n",
    "print(CX, CY, FX, FY)\n",
    "\n",
    "f = open(\"cameras.txt\", \"w\")\n",
    "f.write(f\"1 PINHOLE {width} {height} {FX} {FY} {CX} {CY}\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00.png', '01.png', '02.png', '03.png', '04.png', '05.png', '06.png', '07.png', '08.png', '09.png', '10.png', '11.png', '12.png', '13.png', '14.png', '15.png', '16.png', '17.png', '18.png', '19.png', '20.png', '21.png', '22.png', '23.png', '24.png', '25.png', '26.png', '27.png', '28.png', '29.png', '30.png', '31.png', '32.png', '33.png', '34.png', '35.png', '36.png', '37.png', '38.png', '39.png', '40.png', '41.png', '42.png', '43.png', '44.png', '45.png', '46.png', '47.png', '48.png', '49.png', '50.png', '51.png', '52.png', '53.png', '54.png', '55.png', '56.png', '57.png', '58.png', '59.png']\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "path = r\"D:\\3d-reconstruction\\SplaTAM\\experiments\\iPhone_Captures\\splatam_demo-2\\rgb\"\n",
    "onlyfiles = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "onlyfiles.sort()\n",
    "print(onlyfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # images.txt\n",
    "# # IMAGE_ID, QW, QX, QY, QZ, TX, TY, TZ, CAMERA_ID, NAME\n",
    "\n",
    "# f = open(\"images.txt\", \"w\")\n",
    "\n",
    "# for idx in range(params['cam_unnorm_rots'].shape[2]):\n",
    "#     IMAGE_ID = idx+1\n",
    "\n",
    "#     QW, QX, QY, QZ  = params['cam_unnorm_rots'][:,:,idx].squeeze(0)\n",
    "#     TX, TY, TZ = params['cam_trans'][:,:,idx].squeeze(0) * 10\n",
    "#     CAMERA_ID = 1\n",
    "#     NAME = onlyfiles[idx]\n",
    "\n",
    "#     mylist = ' '.join([str(i) for i in [IMAGE_ID, QW, QX, QY, QZ, TX, TY, TZ, CAMERA_ID, NAME]])\n",
    "\n",
    "#     f.write(mylist+'\\n')\n",
    "\n",
    "#     # dummy\n",
    "#     f.write('0 0 0 0 0 0'+'\\n')\n",
    "\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_matrix_to_quaternion(rotation_matrix):\n",
    "    \"\"\"\n",
    "    Convert a 3x3 rotation matrix to a quaternion.\n",
    "\n",
    "    :param rotation_matrix: A 3x3 numpy array representing the rotation matrix.\n",
    "    :return: A list representing the quaternion in the order [w, x, y, z].\n",
    "    \"\"\"\n",
    "    trace = rotation_matrix[0, 0] + rotation_matrix[1, 1] + rotation_matrix[2, 2]\n",
    "\n",
    "    if trace > 0:\n",
    "        S = np.sqrt(trace + 1.0) * 2\n",
    "        qw = 0.25 * S\n",
    "        qx = (rotation_matrix[2, 1] - rotation_matrix[1, 2]) / S\n",
    "        qy = (rotation_matrix[0, 2] - rotation_matrix[2, 0]) / S\n",
    "        qz = (rotation_matrix[1, 0] - rotation_matrix[0, 1]) / S\n",
    "    elif (rotation_matrix[0, 0] > rotation_matrix[1, 1]) and (rotation_matrix[0, 0] > rotation_matrix[2, 2]):\n",
    "        S = np.sqrt(1.0 + rotation_matrix[0, 0] - rotation_matrix[1, 1] - rotation_matrix[2, 2]) * 2\n",
    "        qw = (rotation_matrix[2, 1] - rotation_matrix[1, 2]) / S\n",
    "        qx = 0.25 * S\n",
    "        qy = (rotation_matrix[0, 1] + rotation_matrix[1, 0]) / S\n",
    "        qz = (rotation_matrix[0, 2] + rotation_matrix[2, 0]) / S\n",
    "    elif rotation_matrix[1, 1] > rotation_matrix[2, 2]:\n",
    "        S = np.sqrt(1.0 + rotation_matrix[1, 1] - rotation_matrix[0, 0] - rotation_matrix[2, 2]) * 2\n",
    "        qw = (rotation_matrix[0, 2] - rotation_matrix[2, 0]) / S\n",
    "        qx = (rotation_matrix[0, 1] + rotation_matrix[1, 0]) / S\n",
    "        qy = 0.25 * S\n",
    "        qz = (rotation_matrix[1, 2] + rotation_matrix[2, 1]) / S\n",
    "    else:\n",
    "        S = np.sqrt(1.0 + rotation_matrix[2, 2] - rotation_matrix[0, 0] - rotation_matrix[1, 1]) * 2\n",
    "        qw = (rotation_matrix[1, 0] - rotation_matrix[0, 1]) / S\n",
    "        qx = (rotation_matrix[0, 2] + rotation_matrix[2, 0]) / S\n",
    "        qy = (rotation_matrix[1, 2] + rotation_matrix[2, 1]) / S\n",
    "        qz = 0.25 * S\n",
    "\n",
    "    return [qw, qx, qy, qz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.0 1.862645149230957e-09 3.725290742551124e-09 -9.313225746154785e-10 0.0 0.0 0.0 1 00.png\n",
      "2 0.9918102538448599 0.1248251643725743 0.021467456399628267 0.016440084884080285 -0.0030356357 -0.07371941 0.013058394 1 01.png\n",
      "3 0.991192837253919 0.1307947450033889 0.01970630983245455 0.006413024411011927 -8.426808e-05 -0.52367675 0.0147223985 1 02.png\n",
      "4 0.9730948259873299 0.2280475360338746 0.018920536491780663 0.02688495165754793 0.024811575 -0.68957746 -0.1317807 1 03.png\n",
      "5 0.9277374588764534 0.367831515266256 0.009008783209280837 0.0626261265673519 0.071061075 -0.63449955 -0.33270422 1 04.png\n",
      "6 0.8182465468676764 0.5637574232788365 0.006159484484291634 0.11230452988329609 0.12537974 -0.43044654 -0.56622684 1 05.png\n",
      "7 0.8978267086191352 0.430666862589467 -0.0019113577241891724 0.09181254597200428 0.25508532 -1.2046912 -1.0969373 1 06.png\n",
      "8 0.9476684972061294 0.3127856608009215 -0.011619602855827655 0.06288470758538245 0.17149061 -1.1836982 -0.78066117 1 07.png\n",
      "9 0.9820379944344401 0.18686622950762016 -0.003623144924381471 0.025869785892145277 0.071656935 -1.259557 -0.46818674 1 08.png\n",
      "10 0.9976103064847435 0.06856586607829143 0.004795190921904876 -0.007029668916950686 -0.00061832764 -1.3198875 -0.19215515 1 09.png\n",
      "11 0.9994042231120318 0.027232139079836834 0.017445445093784467 -0.012057147067348659 0.015209568 -0.90401375 -0.21853158 1 10.png\n",
      "12 0.9996385815293938 0.025682472251626055 0.007927114401291346 -0.0005703661284003155 0.05382532 -0.42115423 -0.28267306 1 11.png\n",
      "13 0.9997608971847278 0.01830053923961083 0.0031981480545913285 -0.011530608224833976 0.056415994 -0.0458542 -0.27299654 1 12.png\n",
      "14 0.9992514132961408 0.037466353771758915 0.00915111374409723 0.0030262763492717496 -0.37528834 0.13398734 -1.1029803 1 13.png\n",
      "15 0.9983117634815853 0.025389276358261995 0.05223923142092316 -0.00029613001160594854 -0.4447852 -0.33209106 -0.96365714 1 14.png\n",
      "16 0.9980786760791713 0.03642185637990475 0.0500033173115882 -0.0034756033588815302 -0.43308753 -0.6465631 -0.9836766 1 15.png\n",
      "17 0.9947620540558697 0.08427118335567876 0.05762347021627759 0.0051374711783471905 -0.44171214 -0.89014906 -1.013087 1 16.png\n",
      "18 0.9755591769743805 0.21274368942436328 0.05399317109824984 0.010451545289196259 -0.4568472 -0.5893016 -1.1819038 1 17.png\n",
      "19 0.8926734456055861 0.4436433500241324 0.04995005462138368 0.06180438362908806 -0.43584254 0.2593923 -1.3097463 1 18.png\n",
      "20 0.8108977144510903 0.5759239508354013 0.04858369710906153 0.0916298303669532 -0.45104426 0.5753941 -1.0982095 1 19.png\n",
      "21 0.7010006921440984 0.7026685577007153 0.04248018201079945 0.1142374606552485 -0.47128397 0.82716495 -0.8223016 1 20.png\n",
      "22 0.6596930193432995 0.7398918407189525 0.03929348696279628 0.1257831800792682 -0.48095307 0.85811085 -0.73077804 1 21.png\n",
      "23 0.6754741632481567 0.6893822765354751 -0.07949139320401706 0.24933475100022967 0.5837655 0.65536463 -0.7410626 1 22.png\n",
      "24 0.6738380431398976 0.6945912166758799 -0.07449892931681266 0.24069761840918144 0.5110108 1.0858783 -0.65898746 1 23.png\n",
      "25 0.7182900989145893 0.6580889097956684 -0.058230694470398824 0.21814561354435535 0.48340768 1.2427057 -0.71446383 1 24.png\n",
      "26 0.8720797787074589 0.4564618054079425 -0.07998611411761138 0.157231297615539 0.70528257 0.46698654 -1.1194409 1 25.png\n",
      "27 0.9696767127678383 0.2216603801919341 -0.09385771795008464 0.04224350144113881 0.65733516 -0.69536555 -1.0968131 1 26.png\n",
      "28 0.9965635201708218 -0.03350722608107792 -0.04082980900117318 -0.06380704895325753 0.23733044 -1.7676852 -0.5593348 1 27.png\n",
      "29 0.9967710996910428 0.054058814604896144 -0.0587121278596012 0.008828399804398798 0.45688698 -1.1694 -0.7369448 1 28.png\n",
      "30 0.9955033890279948 0.033047804034512546 -0.0887530795799222 0.0019474857012134936 0.52078205 -0.7745748 -0.6761624 1 29.png\n",
      "31 0.9943115447182035 0.04992528657705331 -0.09407738063164525 -0.0012015768092725314 0.53606063 -0.34390295 -0.72918534 1 30.png\n",
      "32 0.9942810019440549 0.03746985285754107 -0.09978924182420462 0.006588061798012427 0.5560852 -0.020536546 -0.74194133 1 31.png\n",
      "33 0.9940329982453535 -0.009753492488603617 -0.10850210402137307 0.005527603873015975 0.5606571 0.019052545 -0.7304996 1 32.png\n",
      "34 0.9734992851133225 0.033260992809263354 -0.22561449152154311 0.017057728393120877 1.1176473 0.15749753 -1.0700564 1 33.png\n",
      "35 0.9706230821363337 0.041379545181415345 -0.23666571066621475 0.012958001495835869 1.1188066 -0.23624428 -1.0224428 1 34.png\n",
      "36 0.9731567198300605 0.040146588524094085 -0.22656679783390604 0.004666971475141491 1.0697182 -0.5791064 -1.010051 1 35.png\n",
      "37 0.9739476405626046 0.04316849851615521 -0.22262368865557225 0.0010656700751851727 1.0472986 -0.82397103 -1.0305532 1 36.png\n",
      "38 0.9729299811215248 0.18597943099778327 -0.12238308472375352 0.06197829759012494 1.0217565 -0.37909058 -1.258827 1 37.png\n",
      "39 0.9867084638553263 0.10838352780596942 -0.11793692205755191 -0.027391042698832423 0.7984221 -1.1053636 -1.1861899 1 38.png\n",
      "40 0.9859242433844688 0.07420538368483623 -0.12958498323804973 -0.07519764149902712 0.63241374 -1.5104576 -1.1575375 1 39.png\n",
      "41 0.9826490317825782 0.0107529521431793 -0.12001112712063991 -0.14100553658422643 0.3203846 -1.8244169 -1.0359933 1 40.png\n",
      "42 0.9966277243322066 -0.07152382324716824 0.03887422920525627 -0.010312895770443434 0.03974177 -2.267013 -0.9923881 1 41.png\n",
      "43 0.9999489771224053 0.007741067183617431 0.0015767203934991243 -0.006303384279286776 0.18140814 -1.7253294 -1.3575523 1 42.png\n",
      "44 0.9381366793053532 0.336163914732498 -0.005386936994968894 0.082851624697648 0.35879514 0.095213465 -1.7812527 1 43.png\n",
      "45 0.8316146452336649 0.5383440287016479 -0.007364454752743643 0.13619304115571965 0.218281 1.3090539 -1.2689129 1 44.png\n",
      "46 0.7602928117365857 0.6287692510541599 -0.0569882982057935 0.15282795402776958 0.21393433 1.8373208 -0.67915255 1 45.png\n",
      "47 0.8899552353305946 0.448084113507855 -0.019552679850898248 0.08257150404841573 0.29937375 1.055203 -1.0953989 1 46.png\n",
      "48 0.980142425094202 0.19449231340473855 -0.032034034618563786 0.02161940844069341 0.31969315 0.087756865 -1.4113566 1 47.png\n",
      "49 0.9944633454711578 0.10420315830673942 -0.013350612069270152 0.0024890445305501313 0.26133358 0.055069894 -1.3448732 1 48.png\n",
      "50 0.9996485092415277 0.018993374235557737 -0.006831364918197778 -0.01718798552011595 0.23840033 0.0060075745 -1.3326558 1 49.png\n",
      "51 0.9945720643256236 -0.0975039533265503 -0.010557265834057968 -0.034754795912149666 0.23637785 -0.26712793 -1.2892938 1 50.png\n",
      "52 0.9950581271958001 -0.02020154836172591 -0.09653041035298245 0.011541699682646312 0.34620866 -0.09039167 -0.611144 1 51.png\n",
      "53 0.9975625074013874 0.025451026285757603 -0.06415471821116957 0.010274346365735739 0.3056086 -0.47434643 -0.57993066 1 52.png\n",
      "54 0.9976624944935067 0.046695351235542755 -0.04902291438185723 0.009263512007589207 0.2956149 -0.80192745 -0.55413103 1 53.png\n",
      "55 0.9529806872069138 0.29523732662783897 -0.03116397291275558 0.0607587380984973 0.3358652 -0.2300354 -0.7747696 1 54.png\n",
      "56 0.8716598176839059 0.475236057178782 -0.038592341948532595 0.11344805862164276 0.3433756 0.3822136 -0.7286738 1 55.png\n",
      "57 0.7438247891497426 0.6486474050999237 -0.012009869549175087 0.1607389259526519 0.2310267 0.6329852 -0.46783608 1 56.png\n",
      "58 0.6749379624009193 0.7145191726471819 -0.01562073348572587 0.18351303239257535 0.19707263 0.68578255 -0.32140946 1 57.png\n",
      "59 0.9373320111129283 0.34256413637241456 0.023236623749506507 0.059317536653239224 -0.022661291 -0.017895065 -0.162812 1 58.png\n",
      "60 0.9994966909287956 0.019949759663007344 0.02434797792847053 0.00394356548547234 0.005426736 -0.68416554 -0.0039944723 1 59.png\n"
     ]
    }
   ],
   "source": [
    "# images.txt\n",
    "# IMAGE_ID, QW, QX, QY, QZ, TX, TY, TZ, CAMERA_ID, NAME\n",
    "\n",
    "f = open(\"images.txt\", \"w\")\n",
    "\n",
    "for idx in range(params['gt_w2c_all_frames'].shape[0]):\n",
    "    IMAGE_ID = idx+1\n",
    "\n",
    "    w2c = params['gt_w2c_all_frames'][idx]\n",
    "\n",
    "    R = w2c[:3,:3]\n",
    "    T = w2c[:3, 3]\n",
    "\n",
    "    Qs = rotation_matrix_to_quaternion(R)\n",
    "\n",
    "    CAMERA_ID = 1\n",
    "    NAME = onlyfiles[idx]\n",
    "\n",
    "    mylist = ' '.join([str(i) for i in [IMAGE_ID, Qs[0], Qs[1], Qs[2], Qs[3], T[0], T[1], T[2], CAMERA_ID, NAME]])\n",
    "    print(mylist)\n",
    "\n",
    "    f.write(mylist+'\\n')\n",
    "\n",
    "    # dummy\n",
    "    f.write('0 0 0 0 0 0'+'\\n')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def quaternion_to_rotation_matrix(quaternion):\n",
    "#     \"\"\"     Convert a quaternion to a 3x3 rotation matrix.\n",
    "#     :param quaternion: A list or numpy array representing the quaternion in the order [w, x, y, z].\n",
    "#     :return: A 3x3 numpy array representing the rotation matrix.     \"\"\"\n",
    "#     w, x, y, z = quaternion\n",
    "#     rotation_matrix = np.array([ \n",
    "#         [1 - 2*y**2 - 2*z**2, 2*x*y - 2*z*w, 2*x*z + 2*y*w],\n",
    "#         [2*x*y + 2*z*w, 1 - 2*x**2 - 2*z**2, 2*y*z - 2*x*w],\n",
    "#         [2*x*z - 2*y*w, 2*y*z + 2*x*w, 1 - 2*x**2 - 2*y**2]     ])\n",
    "#     return rotation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # images.txt\n",
    "# # IMAGE_ID, QW, QX, QY, QZ, TX, TY, TZ, CAMERA_ID, NAME\n",
    "\n",
    "# f = open(\"images.txt\", \"w\")\n",
    "\n",
    "# for idx in range(params['cam_unnorm_rots'].shape[2]):\n",
    "#     IMAGE_ID = idx+1\n",
    "\n",
    "#     QW, QX, QY, QZ  = params['cam_unnorm_rots'][:,:,idx].squeeze(0)\n",
    "#     TX, TY, TZ = params['cam_trans'][:,:,idx].squeeze(0)\n",
    "\n",
    "#     rotation_matrix = quaternion_to_rotation_matrix((QW, QX, QY, QZ))\n",
    "#     # print(rotation_matrix.shape)\n",
    "\n",
    "#     Q = np.transpose(rotation_matrix) # (3,3)\n",
    "#     # print(Q.shape)\n",
    "\n",
    "#     T = -Q @ np.array([TX, TY, TZ]).reshape(3,1) # (3,3) @ (3,1)\n",
    "#     # print(T.shape)\n",
    "\n",
    "#     QW, QX, QY, QZ = rotation_matrix_to_quaternion(Q)\n",
    "\n",
    "#     CAMERA_ID = 1\n",
    "#     NAME = onlyfiles[idx]\n",
    "\n",
    "#     mylist = ' '.join([str(i) for i in [IMAGE_ID, QW, QX, QY, QZ, T[0][0], T[1][0], T[2][0], CAMERA_ID, NAME]])\n",
    "\n",
    "#     f.write(mylist+'\\n')\n",
    "\n",
    "#     # dummy\n",
    "#     f.write('0 0 0 0 0 0'+'\\n')\n",
    "\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point3D params\n",
    "xyz     = params['means3D']\n",
    "colors    = params['rgb_colors']\n",
    "rotation  = params['unnorm_rotations']\n",
    "scale     = params['log_scales'].repeat(3, axis=-1)\n",
    "opacity   = params['logit_opacities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"points3D.txt\", \"w\")\n",
    "\n",
    "for idx in range(xyz.shape[0]):\n",
    "    POINT3D_ID = idx+1\n",
    "    X, Y, Z = xyz[idx, :]\n",
    "\n",
    "    R, G, B = colors[idx, :]*255\n",
    "    R, G, B = int(R), int(G), int(B) \n",
    "\n",
    "\n",
    "    # dummy\n",
    "    error = 0\n",
    "    point2d_idx = 0\n",
    "\n",
    "    mylist = ' '.join([str(i) for i in [POINT3D_ID, X, Y, Z, R, G, B, error, point2d_idx, point2d_idx]])\n",
    "\n",
    "    f.write(mylist+'\\n')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Camera rotation each image\n",
    "# cam_unnorm_rots = params['cam_unnorm_rots']\n",
    "# for i in range(10):\n",
    "#     print(cam_unnorm_rots[:,:,i])\n",
    "\n",
    "# # # Camera transform each image\n",
    "# # cam_trans = params['cam_trans']\n",
    "\n",
    "# # for i in range(10):\n",
    "# #     print(cam_trans[:,:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99199367, -0.10957377,  0.06278732,  0.07106107],\n",
       "       [ 0.12282863,  0.7215559 , -0.6813738 , -0.63449955],\n",
       "       [ 0.02935617,  0.6836305 ,  0.7292375 , -0.33270422],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['gt_w2c_all_frames'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "splatam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
